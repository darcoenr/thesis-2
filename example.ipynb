{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10626473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.models as models\n",
    "import core.utils as utils\n",
    "import core.evaluate as evaluate\n",
    "import core.predict as predict\n",
    "import core.test_procedure as test_procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e217e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = 'Exscientia/IgBert'\n",
    "TOKENIZER_CHECKPOINT = 'Exscientia/IgBert'\n",
    "MODEL_NAME = 'average'\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "387b1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_LOCATION = './results/germline_all_evaluation'\n",
    "MODEL_LOCATION = './weights/germline_all.pt'\n",
    "DATASET_LOCATION = './datasets_old/classificator/germline_all/test/test.csv'\n",
    "TEST_DATASET_LOCATION = './datasets_old/test/test.csv'\n",
    "\n",
    "# Dataset parameters\n",
    "shuffle = False     # Shuffle the dataset\n",
    "frac = None         # Get only the specified fraction of the dataset, if None, take the whole\n",
    "                    # dataset unless subsample is specified\n",
    "subsample = 20      # Get a subsample of the specified size\n",
    "batch_size = 4      # Specifies the batch size\n",
    "seed = 0            # The seed in case shuffle, frac or subsample are specified\n",
    "eval_batches = 1    # Number of batches to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336d7f3",
   "metadata": {},
   "source": [
    "### Predict\n",
    "Compute the logits for the VH/VL pair and save the results. \n",
    "\n",
    "Takes as input the location of the fully trained model, the location of the dataset and the output location. \n",
    "\n",
    "The dataset must follow the following format: pair_id,sequence_heavy,sequence_light,label. The label is ignored, hence it can be kept fixed as zero. \n",
    "\n",
    "The results are saved in the following format: pair_id,logit_pos,logit_neg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e78834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the directory ./results/germline_all_evaluation/predict\n",
      "Results location: ./results/germline_all_evaluation/predict\n",
      "Retrieving the dataset...\n",
      "Reading ./datasets_old/classificator/germline_all/test/test.csv...\n",
      "Dataset of size 739194\n",
      "Sampled a subset of size 20\n",
      "Load the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Start evaluating...\n",
      "Number of batches: 5.\n",
      "Select only the first 1 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.54s/it]\n"
     ]
    }
   ],
   "source": [
    "predict.predict(\n",
    "    MODEL_LOCATION, DATASET_LOCATION, \n",
    "    '{}/predict'.format(RESULTS_LOCATION),\n",
    "    shuffle=shuffle, frac=frac, subsample=subsample, batch_size=batch_size, seed=seed,\n",
    "    model_name=MODEL_NAME, model_checkpoint=MODEL_CHECKPOINT, \n",
    "    tokenizer_checkpoint=TOKENIZER_CHECKPOINT,\n",
    "    eval_batches=eval_batches, save=True, out='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1dd15",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "Evaluate a dataset of labeled VH/VL pairs and save the results.\n",
    "\n",
    "Takes as input the location of the fully trained model, the location of the dataset and the output location. \n",
    "\n",
    "The dataset must follow the following format: pair_id,sequence_heavy,sequence_light,label.\n",
    "\n",
    "Two different files re saved:\n",
    "* batch specific metrics;\n",
    "* classification results.\n",
    "\n",
    "Classification results follow the format pair_id,prediction,label where prediction is the label prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e585991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results location: ./results/germline_all_evaluation/evaluate\n",
      "Retrieving the dataset...\n",
      "Reading ./datasets_old/classificator/germline_all/test/test.csv...\n",
      "Dataset of size 739194\n",
      "Sampled a subset of size 20\n",
      "Load the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Start evaluating...\n",
      "Number of batches: 5.\n",
      "Select only the first 1 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.52s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluate.evaluate(MODEL_LOCATION, DATASET_LOCATION, \n",
    "                  '{}/evaluate'.format(RESULTS_LOCATION),\n",
    "                  batch_size=batch_size, shuffle=shuffle, subsample=subsample, frac=frac,\n",
    "                  seed=seed, model_name=MODEL_NAME, model_checkpoint=MODEL_CHECKPOINT,\n",
    "                  tokenizer_checkpoint=TOKENIZER_CHECKPOINT, eval_batches=eval_batches,\n",
    "                  save=True, out='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7da855",
   "metadata": {},
   "source": [
    "### Test procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54cb7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results location: ./results/germline_all_evaluation/test_procedure\n",
      "Retrieving the dataset...\n",
      "Reading ./datasets_old/test/test.csv...\n",
      "Dataset of size 369597\n",
      "Sampled a subset of size 20\n",
      "Load the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Start evaluating...\n",
      "Number of batches: 5.\n",
      "Select only the first 1 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1095819, 1145084,  329745,  708218, 1095819, 1145084,  329745,  708218])\n",
      "tensor([   934, 380061,   1546,  26773,  33113,    201, 663155, 559159])\n",
      "tensor([ 4.9152,  3.1437,  3.8594,  3.3688, -0.7527,  1.1462, -0.7049, -0.2468])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_procedure.test_procedure(MODEL_LOCATION, TEST_DATASET_LOCATION, \n",
    "                              '{}/test_procedure'.format(RESULTS_LOCATION),\n",
    "                              batch_size=batch_size, shuffle=shuffle, subsample=subsample,\n",
    "                              frac=frac, seed=seed, model_name=MODEL_NAME, \n",
    "                              model_checkpoint=MODEL_CHECKPOINT,\n",
    "                              tokenizer_checkpoint=TOKENIZER_CHECKPOINT,\n",
    "                              eval_batches=eval_batches,\n",
    "                              save=True, out='test_procedure')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".thesis_venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
