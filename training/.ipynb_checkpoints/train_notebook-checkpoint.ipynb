{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60f39e2-1f26-481b-9ad0-c804ff24d4e9",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Performs a grid search over the number of layers, size of the layers, learning rate and weight decay.\n",
    "\n",
    "* Number of layers: 3, 5;\n",
    "* Layer size: 1024, 2048;\n",
    "* Learing rate: 1e-3, 5e-4 1e-4 5e-5;\n",
    "* Weight decay: 1e-3, 1e-4, 1e-5.\n",
    "\n",
    "(2x2x4x3 = 48)\n",
    "\n",
    "Each model is trained over the same subset of the training set and evaluated over the same subset of the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1bd47c0-ca3e-4116-a2df-2519cb70117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in cpuinfo: prctl(PR_SVE_GET_VL) failed\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69cf67c9-89cb-4176-b115-2ea00793a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DATASET_DIRECTORY = '../datasets/new/classificator/germline_all'\n",
    "\n",
    "#NUMBER_OF_LAYERS = [3, 5]\n",
    "#LAYER_SIZE = [1024, 2048]\n",
    "#LEARNING_RATE = [1e-3, 5e-4, 1e-4, 5e-5]\n",
    "WEIGHT_DECAY = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "combinations = list(product(NUMBER_OF_LAYERS, LAYER_SIZE, LEARNING_RATE, WEIGHT_DECAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841ce89d-c3ce-495d-abf8-4dbf50445e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d6365-ba01-42c3-b049-c54e66e91eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving the datasets...\n",
      "Reading ../datasets/new/classificator/germline_all/train/train.csv...\n",
      "Dataset of size 1432650\n",
      "Sampled a subset of size 71632\n",
      "Reading ../datasets/new/classificator/germline_all/val/val.csv...\n",
      "Dataset of size 542466\n",
      "Sampled a subset of size 27123\n",
      "Retrieve the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Retrieve the optimizer...\n",
      "Start training...\n",
      "Number of batches: 2239 train, 848 val.\n",
      "Number of epochs: 1\n",
      "Total number of batches that will be used during training: 2239\n",
      "Number of batches for a single evaluation: 10\n",
      "Results are reported every 20 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cuda\n",
      " It.  |               TRAIN               |               EVAL                |\n",
      "------|-----------------------------------|-----------------------------------|\n",
      "      |      loss       |    accuracy     |      loss       |    accuracy     |\n",
      "------|-----------------|-----------------|-----------------|-----------------|\n",
      "    1 | 0.6615 ± 0.0162 | 0.6562 ± 0.0280 | 0.6748 ± 0.0294 | 0.6562 ± 0.0753 |\n",
      "    2 | 0.6567 ± 0.0495 | 0.6000 ± 0.0996 | 0.6580 ± 0.0369 | 0.6062 ± 0.0768 |\n",
      "    3 | 0.6378 ± 0.0442 | 0.5938 ± 0.0862 | 0.6255 ± 0.0550 | 0.6188 ± 0.0976 |\n",
      "    4 | 0.5871 ± 0.0246 | 0.7125 ± 0.0696 | 0.6009 ± 0.0191 | 0.7125 ± 0.0480 |\n",
      "    5 | 0.5420 ± 0.0414 | 0.7188 ± 0.0625 | 0.5563 ± 0.0452 | 0.6719 ± 0.0702 |\n",
      "    6 | 0.5130 ± 0.0106 | 0.7500 ± 0.0442 | 0.5217 ± 0.0547 | 0.7438 ± 0.0696 |\n",
      "    7 | 0.4485 ± 0.0524 | 0.8063 ± 0.0637 | 0.4858 ± 0.0456 | 0.7688 ± 0.0643 |\n",
      "    8 | 0.4232 ± 0.0655 | 0.8500 ± 0.0667 | 0.4246 ± 0.0626 | 0.8313 ± 0.0612 |\n",
      "    9 | 0.4321 ± 0.0449 | 0.7875 ± 0.0459 | 0.4489 ± 0.0942 | 0.7750 ± 0.0946 |\n",
      "   10 | 0.4367 ± 0.0920 | 0.8313 ± 0.0250 | 0.3951 ± 0.0794 | 0.8250 ± 0.0688 |\n",
      "   11 | 0.4089 ± 0.0638 | 0.8187 ± 0.0538 | 0.4277 ± 0.1122 | 0.7969 ± 0.0930 |\n",
      "   12 | 0.3342 ± 0.0751 | 0.8688 ± 0.0667 | 0.3698 ± 0.0661 | 0.8281 ± 0.0546 |\n",
      "   13 | 0.3588 ± 0.1489 | 0.8375 ± 0.1142 | 0.4416 ± 0.0633 | 0.8031 ± 0.0505 |\n",
      "   14 | 0.3639 ± 0.1221 | 0.8562 ± 0.0875 | 0.3928 ± 0.1009 | 0.8094 ± 0.0600 |\n",
      "   15 | 0.3384 ± 0.0922 | 0.8500 ± 0.0573 | 0.4122 ± 0.0560 | 0.8344 ± 0.0371 |\n",
      "   16 | 0.3838 ± 0.1148 | 0.8313 ± 0.0508 | 0.3493 ± 0.0867 | 0.8562 ± 0.0446 |\n",
      "   17 | 0.3486 ± 0.0873 | 0.8562 ± 0.0424 | 0.4237 ± 0.1022 | 0.7969 ± 0.0528 |\n",
      "   18 | 0.3034 ± 0.0513 | 0.9000 ± 0.0364 | 0.3911 ± 0.1100 | 0.8344 ± 0.0594 |\n",
      "   19 | 0.2938 ± 0.0587 | 0.8875 ± 0.0319 | 0.3725 ± 0.0500 | 0.8375 ± 0.0415 |\n",
      "   20 | 0.3031 ± 0.0985 | 0.8625 ± 0.0468 | 0.4437 ± 0.1521 | 0.8063 ± 0.0653 |\n",
      "   21 | 0.2977 ± 0.1172 | 0.8688 ± 0.0538 | 0.3962 ± 0.0922 | 0.8187 ± 0.0696 |\n",
      "   22 | 0.2348 ± 0.0666 | 0.9187 ± 0.0508 | 0.3867 ± 0.1123 | 0.8094 ± 0.0732 |\n",
      "   23 | 0.3428 ± 0.0478 | 0.8750 ± 0.0342 | 0.3635 ± 0.0716 | 0.8156 ± 0.0616 |\n",
      "   24 | 0.3667 ± 0.1219 | 0.8688 ± 0.0538 | 0.3647 ± 0.0856 | 0.8500 ± 0.0556 |\n",
      "   25 | 0.2501 ± 0.0754 | 0.9125 ± 0.0500 | 0.2936 ± 0.0633 | 0.8688 ± 0.0500 |\n",
      "   26 | 0.3131 ± 0.0890 | 0.8750 ± 0.0559 | 0.3541 ± 0.1222 | 0.8688 ± 0.0573 |\n",
      "   27 | 0.2575 ± 0.0438 | 0.8938 ± 0.0319 | 0.3901 ± 0.0810 | 0.8156 ± 0.0493 |\n",
      "   28 | 0.2202 ± 0.0199 | 0.9187 ± 0.0153 | 0.3528 ± 0.1140 | 0.8531 ± 0.0641 |\n",
      "   29 | 0.3040 ± 0.0543 | 0.8625 ± 0.0580 | 0.3803 ± 0.1149 | 0.8250 ± 0.0563 |\n",
      "   30 | 0.2291 ± 0.0655 | 0.8938 ± 0.0424 | 0.3531 ± 0.1237 | 0.8375 ± 0.0622 |\n",
      "   31 | 0.2078 ± 0.0733 | 0.9313 ± 0.0459 | 0.3448 ± 0.0786 | 0.8500 ± 0.0415 |\n",
      "   32 | 0.2178 ± 0.0818 | 0.9187 ± 0.0319 | 0.3033 ± 0.1081 | 0.8719 ± 0.0662 |\n",
      "   33 | 0.2802 ± 0.0788 | 0.8812 ± 0.0696 | 0.3380 ± 0.0611 | 0.8281 ± 0.0320 |\n",
      "   34 | 0.2875 ± 0.0538 | 0.8938 ± 0.0319 | 0.3081 ± 0.1137 | 0.8625 ± 0.0702 |\n",
      "   35 | 0.2131 ± 0.0722 | 0.9062 ± 0.0484 | 0.3222 ± 0.0920 | 0.8688 ± 0.0500 |\n",
      "   36 | 0.1823 ± 0.0600 | 0.9437 ± 0.0364 | 0.3314 ± 0.0828 | 0.8469 ± 0.0549 |\n",
      "   37 | 0.2339 ± 0.0696 | 0.8875 ± 0.0643 | 0.3088 ± 0.0827 | 0.8562 ± 0.0348 |\n",
      "   38 | 0.3024 ± 0.0776 | 0.8938 ± 0.0508 | 0.4067 ± 0.1194 | 0.8125 ± 0.0484 |\n",
      "   39 | 0.2624 ± 0.0549 | 0.9125 ± 0.0306 | 0.2923 ± 0.1356 | 0.8906 ± 0.0629 |\n",
      "   40 | 0.1730 ± 0.0500 | 0.9563 ± 0.0250 | 0.3112 ± 0.1212 | 0.8781 ± 0.0771 |\n",
      "   41 | 0.2625 ± 0.0729 | 0.8688 ± 0.0234 | 0.3784 ± 0.1130 | 0.8406 ± 0.0473 |\n",
      "   42 | 0.2766 ± 0.0735 | 0.8812 ± 0.0364 | 0.3924 ± 0.1230 | 0.8344 ± 0.0560 |\n",
      "   43 | 0.2113 ± 0.0917 | 0.8938 ± 0.0468 | 0.2825 ± 0.0726 | 0.8719 ± 0.0355 |\n",
      "   44 | 0.2449 ± 0.0478 | 0.8938 ± 0.0508 | 0.3501 ± 0.1339 | 0.8313 ± 0.0643 |\n",
      "   45 | 0.2476 ± 0.0743 | 0.9062 ± 0.0593 | 0.2961 ± 0.0747 | 0.8531 ± 0.0465 |\n",
      "   46 | 0.2726 ± 0.0522 | 0.8500 ± 0.0364 | 0.3712 ± 0.1008 | 0.8531 ± 0.0542 |\n",
      "   47 | 0.2305 ± 0.0513 | 0.9125 ± 0.0459 | 0.3100 ± 0.1210 | 0.8719 ± 0.0549 |\n",
      "   48 | 0.2308 ± 0.1060 | 0.8875 ± 0.0755 | 0.3122 ± 0.0941 | 0.8594 ± 0.0716 |\n",
      "   49 | 0.2183 ± 0.1258 | 0.8938 ± 0.0702 | 0.3192 ± 0.1195 | 0.8938 ± 0.0527 |\n",
      "   50 | 0.2836 ± 0.0858 | 0.8812 ± 0.0415 | 0.3334 ± 0.1233 | 0.8969 ± 0.0524 |\n",
      "   51 | 0.2349 ± 0.1443 | 0.9125 ± 0.0500 | 0.2575 ± 0.0885 | 0.9062 ± 0.0559 |\n",
      "   52 | 0.2101 ± 0.0410 | 0.9062 ± 0.0280 | 0.3006 ± 0.0804 | 0.8844 ± 0.0641 |\n",
      "   53 | 0.2794 ± 0.0887 | 0.9000 ± 0.0364 | 0.3315 ± 0.1251 | 0.8562 ± 0.0400 |\n",
      "   54 | 0.1988 ± 0.0675 | 0.9187 ± 0.0580 | 0.3689 ± 0.1626 | 0.8406 ± 0.0758 |\n",
      "   55 | 0.2886 ± 0.1469 | 0.8812 ± 0.0415 | 0.3505 ± 0.1543 | 0.8438 ± 0.0656 |\n",
      "   56 | 0.2859 ± 0.0885 | 0.8938 ± 0.0319 | 0.2810 ± 0.0723 | 0.8812 ± 0.0459 |\n",
      "   57 | 0.2003 ± 0.0587 | 0.9062 ± 0.0342 | 0.2943 ± 0.0587 | 0.8875 ± 0.0400 |\n",
      "   58 | 0.1419 ± 0.0272 | 0.9563 ± 0.0153 | 0.3076 ± 0.1413 | 0.8719 ± 0.0616 |\n",
      "   59 | 0.2428 ± 0.1008 | 0.9000 ± 0.0459 | 0.3224 ± 0.0929 | 0.8625 ± 0.0424 |\n",
      "   60 | 0.2660 ± 0.0823 | 0.8875 ± 0.0580 | 0.3564 ± 0.1474 | 0.8469 ± 0.0844 |\n",
      "   61 | 0.3100 ± 0.1773 | 0.8750 ± 0.0593 | 0.3368 ± 0.1198 | 0.8719 ± 0.0549 |\n",
      "   62 | 0.3317 ± 0.0910 | 0.8750 ± 0.0280 | 0.2411 ± 0.0657 | 0.8938 ± 0.0348 |\n",
      "   63 | 0.2280 ± 0.0688 | 0.8750 ± 0.0442 | 0.2756 ± 0.0827 | 0.9031 ± 0.0493 |\n",
      "   64 | 0.2661 ± 0.1033 | 0.9187 ± 0.0468 | 0.2479 ± 0.0810 | 0.9062 ± 0.0541 |\n",
      "   65 | 0.3215 ± 0.0946 | 0.8562 ± 0.0424 | 0.3638 ± 0.1513 | 0.8500 ± 0.0788 |\n",
      "   66 | 0.2593 ± 0.0592 | 0.9125 ± 0.0234 | 0.3356 ± 0.0869 | 0.8531 ± 0.0560 |\n",
      "   67 | 0.1796 ± 0.0693 | 0.9187 ± 0.0375 | 0.2799 ± 0.0746 | 0.8875 ± 0.0545 |\n",
      "   68 | 0.2021 ± 0.0567 | 0.9437 ± 0.0306 | 0.3310 ± 0.0678 | 0.8688 ± 0.0390 |\n",
      "   69 | 0.2452 ± 0.0610 | 0.8688 ± 0.0415 | 0.2703 ± 0.0499 | 0.8875 ± 0.0563 |\n",
      "   70 | 0.2900 ± 0.1638 | 0.9062 ± 0.0791 | 0.2836 ± 0.0928 | 0.8875 ± 0.0375 |\n",
      "   71 | 0.3147 ± 0.0699 | 0.8938 ± 0.0319 | 0.3604 ± 0.1404 | 0.8438 ± 0.0685 |\n",
      "   72 | 0.1903 ± 0.0743 | 0.9375 ± 0.0342 | 0.3393 ± 0.1349 | 0.8562 ± 0.0488 |\n",
      "   73 | 0.1674 ± 0.0550 | 0.9375 ± 0.0442 | 0.3047 ± 0.0971 | 0.8812 ± 0.0538 |\n",
      "   74 | 0.1371 ± 0.0340 | 0.9563 ± 0.0153 | 0.2962 ± 0.0925 | 0.8906 ± 0.0489 |\n",
      "   75 | 0.1699 ± 0.1129 | 0.9500 ± 0.0375 | 0.3296 ± 0.1318 | 0.8469 ± 0.0732 |\n",
      "   76 | 0.3022 ± 0.1534 | 0.8938 ± 0.0468 | 0.3327 ± 0.1280 | 0.8406 ± 0.0691 |\n",
      "   77 | 0.2775 ± 0.1601 | 0.8875 ± 0.0702 | 0.3004 ± 0.1111 | 0.8594 ± 0.0489 |\n",
      "   78 | 0.2118 ± 0.0700 | 0.9062 ± 0.0523 | 0.2798 ± 0.0695 | 0.8875 ± 0.0375 |\n",
      "   79 | 0.2132 ± 0.1246 | 0.9250 ± 0.0375 | 0.3264 ± 0.1092 | 0.8781 ± 0.0600 |\n",
      "   80 | 0.2179 ± 0.0504 | 0.9125 ± 0.0234 | 0.2117 ± 0.0478 | 0.9062 ± 0.0312 |\n",
      "   81 | 0.2247 ± 0.0859 | 0.8812 ± 0.0459 | 0.2927 ± 0.1048 | 0.8688 ± 0.0556 |\n",
      "   82 | 0.1640 ± 0.0393 | 0.9250 ± 0.0250 | 0.3186 ± 0.1202 | 0.8844 ± 0.0443 |\n",
      "   83 | 0.1779 ± 0.0500 | 0.9125 ± 0.0459 | 0.3511 ± 0.0948 | 0.8531 ± 0.0344 |\n",
      "   84 | 0.1756 ± 0.0700 | 0.9125 ± 0.0538 | 0.2771 ± 0.0787 | 0.8844 ± 0.0560 |\n",
      "   85 | 0.2453 ± 0.0984 | 0.9062 ± 0.0395 | 0.3096 ± 0.1437 | 0.8635 ± 0.0625 |\n",
      "   86 | 0.1807 ± 0.0607 | 0.9062 ± 0.0342 | 0.2304 ± 0.0748 | 0.9125 ± 0.0459 |\n",
      "   87 | 0.2509 ± 0.0953 | 0.9250 ± 0.0319 | 0.3342 ± 0.1197 | 0.8625 ± 0.0628 |\n",
      "   88 | 0.2455 ± 0.1172 | 0.8938 ± 0.0545 | 0.3384 ± 0.0970 | 0.8594 ± 0.0469 |\n",
      "   89 | 0.2550 ± 0.0932 | 0.9062 ± 0.0280 | 0.3224 ± 0.0887 | 0.8531 ± 0.0371 |\n",
      "   90 | 0.1911 ± 0.0683 | 0.9125 ± 0.0459 | 0.2713 ± 0.0946 | 0.9125 ± 0.0337 |\n",
      "   91 | 0.2282 ± 0.1289 | 0.9125 ± 0.0723 | 0.2483 ± 0.1418 | 0.8844 ± 0.0656 |\n",
      "   92 | 0.2822 ± 0.1603 | 0.9062 ± 0.0523 | 0.3533 ± 0.0430 | 0.8625 ± 0.0375 |\n",
      "   93 | 0.1570 ± 0.0560 | 0.9437 ± 0.0415 | 0.2748 ± 0.1307 | 0.8969 ± 0.0577 |\n",
      "   94 | 0.1945 ± 0.0553 | 0.9563 ± 0.0153 | 0.2981 ± 0.1119 | 0.8688 ± 0.0653 |\n",
      "   95 | 0.2764 ± 0.0580 | 0.8750 ± 0.0198 | 0.2826 ± 0.0835 | 0.8875 ± 0.0400 |\n",
      "   96 | 0.2371 ± 0.0760 | 0.9062 ± 0.0559 | 0.2597 ± 0.1347 | 0.9031 ± 0.0531 |\n",
      "   97 | 0.2040 ± 0.0962 | 0.9313 ± 0.0500 | 0.2966 ± 0.1116 | 0.8719 ± 0.0632 |\n",
      "   98 | 0.2924 ± 0.1130 | 0.9000 ± 0.0459 | 0.3342 ± 0.1106 | 0.8594 ± 0.0613 |\n",
      "   99 | 0.2242 ± 0.1173 | 0.9062 ± 0.0713 | 0.2865 ± 0.0578 | 0.8625 ± 0.0628 |\n",
      "  100 | 0.2297 ± 0.0946 | 0.9187 ± 0.0545 | 0.3166 ± 0.0872 | 0.8750 ± 0.0419 |\n",
      "  101 | 0.2198 ± 0.1107 | 0.9187 ± 0.0545 | 0.2683 ± 0.1366 | 0.9000 ± 0.0637 |\n",
      "  102 | 0.2602 ± 0.1176 | 0.8875 ± 0.0545 | 0.2299 ± 0.0680 | 0.8969 ± 0.0344 |\n",
      "  103 | 0.2028 ± 0.0752 | 0.9313 ± 0.0364 | 0.2566 ± 0.0863 | 0.9000 ± 0.0415 |\n",
      "  104 | 0.2612 ± 0.0953 | 0.9187 ± 0.0375 | 0.2785 ± 0.0966 | 0.8781 ± 0.0531 |\n",
      "  105 | 0.1912 ± 0.0840 | 0.9437 ± 0.0538 | 0.2794 ± 0.1188 | 0.8906 ± 0.0597 |\n",
      "  106 | 0.3171 ± 0.0656 | 0.8875 ± 0.0250 | 0.2910 ± 0.1113 | 0.8562 ± 0.0742 |\n",
      "  107 | 0.2525 ± 0.0455 | 0.9000 ± 0.0234 | 0.2708 ± 0.1172 | 0.8875 ± 0.0628 |\n",
      "  108 | 0.2721 ± 0.0697 | 0.9187 ± 0.0375 | 0.3409 ± 0.0888 | 0.8438 ± 0.0395 |\n",
      "  109 | 0.1476 ± 0.0573 | 0.9500 ± 0.0319 | 0.2613 ± 0.1029 | 0.8969 ± 0.0542 |\n",
      "  110 | 0.1650 ± 0.0454 | 0.9250 ± 0.0319 | 0.2165 ± 0.0720 | 0.9062 ± 0.0442 |\n",
      "  111 | 0.1529 ± 0.0505 | 0.9500 ± 0.0319 | 0.3291 ± 0.1302 | 0.8562 ± 0.0643 |\n",
      "Retrieving the datasets...\n",
      "Reading ../datasets/new/classificator/germline_all/train/train.csv...\n",
      "Dataset of size 1432650\n",
      "Sampled a subset of size 71632\n",
      "Reading ../datasets/new/classificator/germline_all/val/val.csv...\n",
      "Dataset of size 542466\n",
      "Sampled a subset of size 27123\n",
      "Retrieve the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Retrieve the optimizer...\n",
      "Start training...\n",
      "Number of batches: 2239 train, 848 val.\n",
      "Number of epochs: 1\n",
      "Total number of batches that will be used during training: 2239\n",
      "Number of batches for a single evaluation: 10\n",
      "Results are reported every 20 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cuda\n",
      " It.  |               TRAIN               |               EVAL                |\n",
      "------|-----------------------------------|-----------------------------------|\n",
      "      |      loss       |    accuracy     |      loss       |    accuracy     |\n",
      "------|-----------------|-----------------|-----------------|-----------------|\n",
      "    1 | 0.6596 ± 0.0137 | 0.5813 ± 0.0755 | 0.6670 ± 0.0395 | 0.5625 ± 0.0670 |\n",
      "    2 | 0.6405 ± 0.0167 | 0.6562 ± 0.0815 | 0.6541 ± 0.0319 | 0.6094 ± 0.0950 |\n",
      "    3 | 0.6326 ± 0.0237 | 0.5938 ± 0.0280 | 0.6327 ± 0.0614 | 0.5969 ± 0.1031 |\n",
      "    4 | 0.5887 ± 0.0290 | 0.6750 ± 0.0875 | 0.5943 ± 0.0439 | 0.6406 ± 0.0702 |\n",
      "    5 | 0.5004 ± 0.0407 | 0.7438 ± 0.0538 | 0.5267 ± 0.0545 | 0.7562 ± 0.0813 |\n",
      "    6 | 0.4824 ± 0.0751 | 0.8063 ± 0.0824 | 0.4672 ± 0.0409 | 0.8344 ± 0.0524 |\n",
      "    7 | 0.4307 ± 0.0434 | 0.8063 ± 0.0637 | 0.4356 ± 0.0498 | 0.8500 ± 0.0556 |\n",
      "    8 | 0.4039 ± 0.0585 | 0.8500 ± 0.0538 | 0.4043 ± 0.0917 | 0.8406 ± 0.0616 |\n",
      "    9 | 0.3518 ± 0.0428 | 0.8625 ± 0.0375 | 0.4716 ± 0.1398 | 0.7906 ± 0.0656 |\n",
      "   10 | 0.4100 ± 0.1188 | 0.8438 ± 0.0685 | 0.4295 ± 0.1033 | 0.8063 ± 0.0776 |\n",
      "   11 | 0.3597 ± 0.0832 | 0.8438 ± 0.0625 | 0.4467 ± 0.0952 | 0.8250 ± 0.0673 |\n",
      "   12 | 0.3560 ± 0.0766 | 0.8500 ± 0.0606 | 0.3903 ± 0.0877 | 0.8531 ± 0.0542 |\n",
      "   13 | 0.2962 ± 0.0711 | 0.9125 ± 0.0500 | 0.3890 ± 0.0789 | 0.8156 ± 0.0493 |\n",
      "   14 | 0.2697 ± 0.0585 | 0.8938 ± 0.0424 | 0.4023 ± 0.0743 | 0.7969 ± 0.0613 |\n",
      "   15 | 0.3862 ± 0.1506 | 0.8500 ± 0.0996 | 0.4031 ± 0.1236 | 0.8156 ± 0.0705 |\n",
      "   16 | 0.3708 ± 0.0955 | 0.8438 ± 0.0593 | 0.3855 ± 0.1028 | 0.8187 ± 0.0637 |\n",
      "   17 | 0.3258 ± 0.0758 | 0.8625 ± 0.0319 | 0.3466 ± 0.0480 | 0.8562 ± 0.0508 |\n",
      "   18 | 0.3496 ± 0.1068 | 0.8438 ± 0.0656 | 0.4586 ± 0.1178 | 0.7906 ± 0.0485 |\n",
      "   19 | 0.2896 ± 0.0423 | 0.8688 ± 0.0234 | 0.4130 ± 0.0855 | 0.8125 ± 0.0504 |\n",
      "   20 | 0.2988 ± 0.0678 | 0.8688 ± 0.0538 | 0.3740 ± 0.0843 | 0.8406 ± 0.0513 |\n",
      "   21 | 0.3831 ± 0.1133 | 0.8438 ± 0.0656 | 0.3982 ± 0.0771 | 0.8125 ± 0.0753 |\n",
      "   22 | 0.3068 ± 0.0856 | 0.8562 ± 0.0673 | 0.3531 ± 0.0831 | 0.8344 ± 0.0560 |\n",
      "   23 | 0.2735 ± 0.1300 | 0.8875 ± 0.0805 | 0.3227 ± 0.1126 | 0.8656 ± 0.0873 |\n",
      "   24 | 0.2575 ± 0.0454 | 0.8875 ± 0.0319 | 0.3527 ± 0.0967 | 0.8313 ± 0.0545 |\n",
      "   25 | 0.2957 ± 0.0805 | 0.8562 ± 0.0729 | 0.3898 ± 0.1185 | 0.8219 ± 0.0656 |\n",
      "   26 | 0.2089 ± 0.0584 | 0.9187 ± 0.0468 | 0.3458 ± 0.1255 | 0.8281 ± 0.0730 |\n",
      "   27 | 0.3090 ± 0.0893 | 0.8688 ± 0.0364 | 0.3486 ± 0.1160 | 0.8219 ± 0.0594 |\n",
      "   28 | 0.2641 ± 0.0385 | 0.8625 ± 0.0153 | 0.2926 ± 0.0426 | 0.8750 ± 0.0395 |\n",
      "   29 | 0.3102 ± 0.0607 | 0.8688 ± 0.0415 | 0.3511 ± 0.1376 | 0.8469 ± 0.0758 |\n",
      "   30 | 0.1995 ± 0.0629 | 0.9187 ± 0.0375 | 0.3659 ± 0.1392 | 0.8406 ± 0.0758 |\n",
      "   31 | 0.2797 ± 0.0838 | 0.8625 ± 0.0468 | 0.3643 ± 0.0871 | 0.8375 ± 0.0573 |\n",
      "   32 | 0.2526 ± 0.0740 | 0.8750 ± 0.0656 | 0.3501 ± 0.0608 | 0.8406 ± 0.0295 |\n",
      "   33 | 0.2578 ± 0.0355 | 0.8938 ± 0.0153 | 0.3360 ± 0.1064 | 0.8656 ± 0.0542 |\n",
      "   34 | 0.3172 ± 0.0866 | 0.8750 ± 0.0280 | 0.3284 ± 0.1143 | 0.8500 ± 0.0480 |\n",
      "   35 | 0.2353 ± 0.0797 | 0.8875 ± 0.0643 | 0.3302 ± 0.1253 | 0.8469 ± 0.0616 |\n",
      "   36 | 0.2657 ± 0.0592 | 0.9000 ± 0.0306 | 0.3547 ± 0.1258 | 0.8688 ± 0.0480 |\n",
      "   37 | 0.2621 ± 0.0637 | 0.8938 ± 0.0468 | 0.3585 ± 0.0694 | 0.8562 ± 0.0400 |\n",
      "   38 | 0.2562 ± 0.0876 | 0.8562 ± 0.0643 | 0.3692 ± 0.0787 | 0.8313 ± 0.0286 |\n",
      "   39 | 0.2221 ± 0.0527 | 0.9062 ± 0.0280 | 0.3639 ± 0.0759 | 0.8375 ± 0.0272 |\n",
      "   40 | 0.2072 ± 0.0551 | 0.9250 ± 0.0319 | 0.2553 ± 0.1046 | 0.9125 ± 0.0556 |\n",
      "   41 | 0.2631 ± 0.1104 | 0.8938 ± 0.0508 | 0.3303 ± 0.1064 | 0.8375 ± 0.0737 |\n",
      "   42 | 0.2654 ± 0.0944 | 0.9125 ± 0.0364 | 0.2865 ± 0.1103 | 0.8750 ± 0.0464 |\n",
      "   43 | 0.2778 ± 0.0469 | 0.9062 ± 0.0198 | 0.3096 ± 0.0451 | 0.8562 ± 0.0468 |\n",
      "   44 | 0.2515 ± 0.1008 | 0.9062 ± 0.0625 | 0.3147 ± 0.1046 | 0.8781 ± 0.0473 |\n",
      "   45 | 0.2123 ± 0.0422 | 0.9187 ± 0.0424 | 0.2679 ± 0.0898 | 0.8906 ± 0.0563 |\n",
      "   46 | 0.2793 ± 0.0516 | 0.8812 ± 0.0459 | 0.2917 ± 0.0647 | 0.8938 ± 0.0400 |\n",
      "   47 | 0.2261 ± 0.0386 | 0.9000 ± 0.0415 | 0.3112 ± 0.0814 | 0.8688 ± 0.0437 |\n",
      "   48 | 0.1868 ± 0.0914 | 0.9187 ± 0.0508 | 0.3332 ± 0.1495 | 0.8750 ± 0.0765 |\n",
      "   49 | 0.2760 ± 0.0640 | 0.8750 ± 0.0342 | 0.3080 ± 0.1371 | 0.8688 ± 0.0696 |\n",
      "   50 | 0.2999 ± 0.0684 | 0.8875 ± 0.0545 | 0.3449 ± 0.0974 | 0.8625 ± 0.0643 |\n",
      "   51 | 0.1972 ± 0.0615 | 0.9250 ± 0.0250 | 0.2919 ± 0.0923 | 0.8688 ± 0.0306 |\n",
      "   52 | 0.2252 ± 0.1107 | 0.9187 ± 0.0643 | 0.2734 ± 0.0964 | 0.8906 ± 0.0580 |\n",
      "   53 | 0.2155 ± 0.0515 | 0.9187 ± 0.0319 | 0.2925 ± 0.0687 | 0.8875 ± 0.0508 |\n",
      "   54 | 0.3010 ± 0.1114 | 0.8750 ± 0.0280 | 0.3548 ± 0.1416 | 0.8531 ± 0.0671 |\n",
      "   55 | 0.2131 ± 0.0469 | 0.9062 ± 0.0342 | 0.3277 ± 0.0735 | 0.8594 ± 0.0425 |\n",
      "   56 | 0.2831 ± 0.1312 | 0.8875 ± 0.0643 | 0.3290 ± 0.1291 | 0.8594 ± 0.0644 |\n",
      "   57 | 0.2584 ± 0.0948 | 0.8938 ± 0.0250 | 0.3402 ± 0.1081 | 0.8594 ± 0.0425 |\n",
      "   58 | 0.2270 ± 0.0953 | 0.9000 ± 0.0750 | 0.2930 ± 0.0860 | 0.8594 ± 0.0597 |\n",
      "   59 | 0.2597 ± 0.0743 | 0.8812 ± 0.0306 | 0.2885 ± 0.1182 | 0.8844 ± 0.0610 |\n",
      "   60 | 0.2307 ± 0.0634 | 0.9062 ± 0.0484 | 0.3689 ± 0.1422 | 0.8719 ± 0.0677 |\n",
      "   61 | 0.2265 ± 0.0712 | 0.9062 ± 0.0198 | 0.3052 ± 0.0867 | 0.8688 ± 0.0480 |\n",
      "   62 | 0.2661 ± 0.1272 | 0.9062 ± 0.0765 | 0.3302 ± 0.1202 | 0.8656 ± 0.0560 |\n",
      "   63 | 0.2415 ± 0.0474 | 0.8938 ± 0.0424 | 0.3298 ± 0.0980 | 0.8875 ± 0.0527 |\n",
      "   64 | 0.2012 ± 0.0954 | 0.9062 ± 0.0685 | 0.3258 ± 0.1115 | 0.8688 ± 0.0590 |\n",
      "   65 | 0.1326 ± 0.0496 | 0.9563 ± 0.0319 | 0.3252 ± 0.1141 | 0.8750 ± 0.0419 |\n",
      "   66 | 0.3108 ± 0.1558 | 0.9000 ± 0.0500 | 0.3035 ± 0.0778 | 0.8812 ± 0.0364 |\n",
      "   67 | 0.3134 ± 0.1020 | 0.8500 ± 0.0500 | 0.3429 ± 0.0870 | 0.8406 ± 0.0531 |\n",
      "   68 | 0.2859 ± 0.0661 | 0.8875 ± 0.0375 | 0.2848 ± 0.1288 | 0.8719 ± 0.0662 |\n",
      "   69 | 0.2261 ± 0.0801 | 0.9250 ± 0.0153 | 0.3298 ± 0.1116 | 0.8500 ± 0.0710 |\n",
      "   70 | 0.2384 ± 0.0328 | 0.9062 ± 0.0198 | 0.2437 ± 0.0705 | 0.8969 ± 0.0420 |\n",
      "   71 | 0.2088 ± 0.0817 | 0.9375 ± 0.0342 | 0.3356 ± 0.0729 | 0.8750 ± 0.0541 |\n",
      "   72 | 0.2089 ± 0.0829 | 0.9313 ± 0.0364 | 0.3364 ± 0.1044 | 0.8719 ± 0.0473 |\n",
      "   73 | 0.2228 ± 0.0732 | 0.9313 ± 0.0364 | 0.3673 ± 0.0715 | 0.8625 ± 0.0468 |\n",
      "   74 | 0.2395 ± 0.0804 | 0.9125 ± 0.0415 | 0.2817 ± 0.1066 | 0.9000 ± 0.0438 |\n",
      "   75 | 0.1951 ± 0.0638 | 0.9437 ± 0.0306 | 0.2620 ± 0.1060 | 0.8812 ± 0.0459 |\n",
      "   76 | 0.1666 ± 0.0874 | 0.9375 ± 0.0442 | 0.3478 ± 0.0975 | 0.8625 ± 0.0424 |\n",
      "   77 | 0.2459 ± 0.0912 | 0.9000 ± 0.0459 | 0.2618 ± 0.0741 | 0.9000 ± 0.0438 |\n",
      "   78 | 0.2073 ± 0.0784 | 0.9313 ± 0.0306 | 0.3131 ± 0.0904 | 0.8594 ± 0.0376 |\n",
      "   79 | 0.2610 ± 0.1230 | 0.9062 ± 0.0342 | 0.3465 ± 0.1497 | 0.8531 ± 0.0626 |\n",
      "   80 | 0.2166 ± 0.0886 | 0.9187 ± 0.0508 | 0.3358 ± 0.0768 | 0.8438 ± 0.0242 |\n",
      "   81 | 0.1986 ± 0.0825 | 0.9250 ± 0.0250 | 0.2812 ± 0.0966 | 0.8781 ± 0.0452 |\n",
      "   82 | 0.2626 ± 0.0438 | 0.8812 ± 0.0234 | 0.2704 ± 0.0910 | 0.8812 ± 0.0682 |\n",
      "   83 | 0.2151 ± 0.0729 | 0.9125 ± 0.0415 | 0.2522 ± 0.0989 | 0.9094 ± 0.0493 |\n",
      "   84 | 0.2659 ± 0.0856 | 0.9062 ± 0.0198 | 0.2325 ± 0.0528 | 0.9062 ± 0.0370 |\n"
     ]
    }
   ],
   "source": [
    "for i, (number_of_layers, layer_size, learning_rate, weight_decay) in enumerate(combinations[START:], START):\n",
    "    parameters_dict = {\n",
    "        'train_data_location': '{}/train/train.csv'.format(MAIN_DATASET_DIRECTORY),\n",
    "        'val_data_location': '{}/val/val.csv'.format(MAIN_DATASET_DIRECTORY),\n",
    "        'subsample': None,\n",
    "        'frac': 0.05,\n",
    "        'shuffle': True,\n",
    "        'batch_size': 32,\n",
    "\n",
    "        'model_name': 'average',\n",
    "        'model_checkpoint': 'Exscientia/IgBert',\n",
    "        'tokenizer_checkpoint': None,\n",
    "        'number_of_layers': number_of_layers,\n",
    "        'layer_size':layer_size,\n",
    "\n",
    "        'optimizer_name': 'adam',\n",
    "        'lr': learning_rate,\n",
    "        'momentum': 0,\n",
    "        'weight_decay': weight_decay,\n",
    "\n",
    "        'n_epochs': 1,\n",
    "        'train_batches': 3000,\n",
    "        'eval_batches': 10,\n",
    "\n",
    "        'evaluate_every': 20,\n",
    "        'mean_lasts': 5,\n",
    "    \n",
    "        'save': True,\n",
    "        'name': 'grid_search_1/{}'.format(i)\n",
    "    }\n",
    "    train.train(**parameters_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeedf4ae-24aa-4188-a01c-0ca3b0d82a89",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9d5d44-642d-496e-8ca9-0f2588e73dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in cpuinfo: prctl(PR_SVE_GET_VL) failed\n"
     ]
    }
   ],
   "source": [
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3486395-5676-435d-9864-f2cc92fe73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'train_data_location': '../datasets/new/classificator/train/train.csv',\n",
    "    'val_data_location': '../datasets/new/classificator/val/val.csv',\n",
    "    'subsample': None,\n",
    "    'frac': 0.05,\n",
    "    'shuffle': True,\n",
    "    'seed': 54321,\n",
    "    'batch_size': 32,\n",
    "\n",
    "    'model_name': 'average',\n",
    "    'model_checkpoint': 'Exscientia/IgBert',\n",
    "    'tokenizer_checkpoint': None,\n",
    "    'number_of_layers': 5,\n",
    "    'layer_size':2048,\n",
    "\n",
    "    'optimizer_name': 'adam',\n",
    "    'lr': 1e-4,\n",
    "    'momentum': 0,\n",
    "    'weight_decay': 1e-3,\n",
    "    'beta1': 0.9\n",
    "    'beta2': 0.999\n",
    "\n",
    "    #'lr_scheduler_name': 'plateau',\n",
    "    #'factor': 0.9,\n",
    "    #'min_lr': 1e-6,\n",
    "    #'patience': 10,\n",
    "\n",
    "    #'lr_scheduler_name': 'exponential',\n",
    "    #'lr_update_every': 5,\n",
    "    #'gamma': 0.9,\n",
    "\n",
    "    'n_epochs': 1,\n",
    "    'train_batches': 3000,\n",
    "    'eval_batches': 10,\n",
    "\n",
    "    'evaluate_every': 20,\n",
    "    'mean_lasts': 5,\n",
    "    \n",
    "    'save': True,\n",
    "    'name': 'grid_search_capacity/3_2048'\n",
    "}\n",
    "\n",
    "COMPUTE_NEW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf7d27b-25b5-46fb-b2a6-e5c6b7922bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving the datasets...\n",
      "Reading ../datasets/new/classificator/train/train.csv...\n",
      "Dataset of size 1432650\n",
      "Sampled a subset of size 71632\n",
      "Reading ../datasets/new/classificator/val/val.csv...\n",
      "Dataset of size 542466\n",
      "Sampled a subset of size 27123\n",
      "Retrieve the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Retrieve the optimizer...\n",
      "Start training...\n",
      "Number of batches: 2239 train, 848 val.\n",
      "Number of epochs: 1\n",
      "Total number of batches that will be used during training: 3000\n",
      "Number of batches for a single evaluation: 10\n",
      "Results are reported every 20 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cuda\n",
      " It.  |               TRAIN               |               EVAL                |\n",
      "------|-----------------------------------|-----------------------------------|\n",
      "      |      loss       |    accuracy     |      loss       |    accuracy     |\n",
      "------|-----------------|-----------------|-----------------|-----------------|\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m COMPUTE_NEW: train\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters_dict)\n",
      "File \u001b[0;32m/disk1/e.darco/thesis/training/train.py:125\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_data_location, val_data_location, shuffle, subsample, frac, seed, batch_size, model_name, model_checkpoint, tokenizer_checkpoint, number_of_layers, layer_size, optimizer_name, lr, momentum, weight_decay, n_epochs, train_batches, eval_batches, evaluate_every, mean_lasts, lr_scheduler_name, factor, patience, min_lr, gamma, last_epoch, save, name)\u001b[0m\n\u001b[1;32m    121\u001b[0m hyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_last\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mean_lasts\n\u001b[1;32m    123\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m--> 125\u001b[0m model, results_train, results_eval \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluate_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_lasts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_lasts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_score\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[1;32m    134\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/classification/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/disk1/e.darco/thesis/training/utils.py:422\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, sched, train_dl, eval_dl, n_epochs, train_batches, eval_batches, evaluate_every, mean_lasts, metrics, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m     eval_it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(eval_dl)\n\u001b[1;32m    421\u001b[0m     eval_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(eval_it)\n\u001b[0;32m--> 422\u001b[0m eval_dict \u001b[38;5;241m=\u001b[39m \u001b[43minfer_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m eval_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    425\u001b[0m     eval_results_batches[key]\u001b[38;5;241m.\u001b[39mappend(value)\n",
      "File \u001b[0;32m/disk1/e.darco/thesis/training/utils.py:301\u001b[0m, in \u001b[0;36minfer_batch\u001b[0;34m(model, criterion, optimizer, batch, tokenizer, metrics, device, return_classification_results)\u001b[0m\n\u001b[1;32m    298\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minput_dict)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtraining:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if COMPUTE_NEW: train.train(**parameters_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66989b5-ccb7-4cbd-ab36-ec26b58901b2",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6faa2171-eb6b-4ae5-b674-95d1e5e3ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in cpuinfo: prctl(PR_SVE_GET_VL) failed\n"
     ]
    }
   ],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1080e083-0da1-49f9-982a-f7e6cdf5b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DATASET_DIRECTORY = '../datasets/new/classificator/germline_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ef14c9-3298-47d5-914d-c387f20f9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'name': 'grid_search_1/4',\n",
    "    \n",
    "    'val_data': '{}/val/val.csv'.format(MAIN_DATASET_DIRECTORY),\n",
    "    'subsample': None,\n",
    "    'frac': 0.05,\n",
    "    'shuffle': True,\n",
    "    'batch_size': 32,\n",
    "    'seed': 0,\n",
    "    'eval_batches': None,\n",
    "\n",
    "    'model_name': 'average',\n",
    "    'model_checkpoint': 'Exscientia/IgBert',\n",
    "    'tokenizer_checkpoint': None,\n",
    "    \n",
    "    'save': True,\n",
    "    'out': 'val_results'\n",
    "}\n",
    "\n",
    "COMPUTE_NEW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258eb70c-19a6-465e-b3db-5edf65a79cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: ../results/classification/grid_search_1/4/\n",
      "Retrieving the dataset...\n",
      "Reading ../datasets/new/classificator/germline_all/val/val.csv...\n",
      "Dataset of size 542466\n",
      "Sampled a subset of size 27123\n",
      "Load the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Start evaluating...\n",
      "Number of batches: 848.\n",
      "Select only the first 848 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 848/848 [06:15<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "if COMPUTE_NEW:\n",
    "    importlib.reload(evaluate)\n",
    "    evaluate.evaluate(**parameters_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb722c-f3c7-44ed-b743-98ec2b46fc9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61325be2-b445-4a59-b56d-53429edc1a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import utils\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce20310-219b-46b7-9fa4-797884b71dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '../../datasets/FLAb/data/binding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "340567ab-f728-4aa7-b431-b3e3976228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(DIR) if 'csv' in f]\n",
    "\n",
    "df = pd.concat([pd.read_csv('{}/{}'.format(DIR, f)) for f in files]).reset_index(drop=True)\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "pair_id = list(range(len(df)))\n",
    "\n",
    "df['pair_id'] = pair_id\n",
    "df = df.rename({'fitness': 'class'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13bb3db9-e168-4c0b-986e-fdd7899113b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_MODEL = 'average-germline-only-human-long-training'\n",
    "LOCATION = '../results/classification/{}'.format(WHICH_MODEL)\n",
    "\n",
    "CHECKPOINT = 'Exscientia/IgBert'\n",
    "MODEL_NAME = 'average'\n",
    "\n",
    "TOKENIZER_CHECKPOINT = None\n",
    "if TOKENIZER_CHECKPOINT is None: TOKENIZER_CHECKPOINT = CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "791a596b-a26f-49c3-a44e-9aff50a9e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer checkpoint: Exscientia/IgBert\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('{}/model.pt'.format(LOCATION), weights_only=True)\n",
    "model = utils.load_model(MODEL_NAME, checkpoint=CHECKPOINT, state_dict=state_dict)\n",
    "tokenizer = utils.retrieve_tokenizer(TOKENIZER_CHECKPOINT)\n",
    "data = DataLoader(utils.AbDataset(df), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df3702b1-b234-45eb-8e48-34a5166ca4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b053f9-7ddb-4e1a-a333-2bfd4c66172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(data, total=len(data)):\n",
    "        _, inputs, value = batch[0], batch[1], batch[2]\n",
    "        input_dict = utils.tokenize_inputs(inputs, tokenizer, device=device)\n",
    "        logits = model(**input_dict)\n",
    "        print(softmax(logits, dim=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2061ce-5734-4fd6-9c00-6bf946ac4b7a",
   "metadata": {},
   "source": [
    "### Evalute pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356f5a99-3a0a-421c-b850-eedc70b31b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in cpuinfo: prctl(PR_SVE_GET_VL) failed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a09693c-2316-4dc8-a0d7-ee7314683336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>heavy_id</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light_id_pos</th>\n",
       "      <th>light_pos</th>\n",
       "      <th>light_id_neg</th>\n",
       "      <th>light_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605842</td>\n",
       "      <td>604074</td>\n",
       "      <td>QVQLQESGPGLVKPSETLSLTCTVSGGSISSYYWSWIRQPPGKGLE...</td>\n",
       "      <td>3608</td>\n",
       "      <td>SYVLTQPPSVSVAPGKTARITCGGNNIGSKSVHWYQQKPGQAPVLV...</td>\n",
       "      <td>338246</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSISNYLNWYQQKPEKVPKL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1588716</td>\n",
       "      <td>1570796</td>\n",
       "      <td>QVQLVQSGAEVKTPEASVKLSCKTSGYTFTSYYIHWVRQAPGQGLE...</td>\n",
       "      <td>201867</td>\n",
       "      <td>QAVVTQEPSLTVSPGGTVTLTCGSSTGAVTSGHYPYWFQQKPGQAP...</td>\n",
       "      <td>581364</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRASQSFSRWLAWYQQKPGKAPKL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>934058</td>\n",
       "      <td>931467</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLE...</td>\n",
       "      <td>723</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...</td>\n",
       "      <td>545684</td>\n",
       "      <td>SYVLTQPPSVSVAPGQTATITCGGNNIGSKVVHWYQQRPGQAPILV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1047359</td>\n",
       "      <td>1044321</td>\n",
       "      <td>EVQLVESGGGLVKPGGSLRLSCAASGFTFSNAWMSWVRQAPGKGLE...</td>\n",
       "      <td>327738</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...</td>\n",
       "      <td>28102</td>\n",
       "      <td>QPVLTQPPSASASLGASVTLTCTLSSGYSNYKVDWYQQRPGKGPRF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>761110</td>\n",
       "      <td>758895</td>\n",
       "      <td>QVQLVQSGDEVREPGASVKVSCKASGDTLSSHGVTWVRQAPGQRLE...</td>\n",
       "      <td>268698</td>\n",
       "      <td>DVQMTQSPSTLSASVGDRVTITCRASQSISRSLAWYQQHPGRVPKL...</td>\n",
       "      <td>302895</td>\n",
       "      <td>QSVLTQPPSVSGAPGQTVTISCTGSSSNIGAGYDVHWYQQLPGTAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369592</th>\n",
       "      <td>1350039</td>\n",
       "      <td>1340727</td>\n",
       "      <td>QVQLVQSGTEVKKPGASVTVSCKAAGYTFANYGVSWVRQAPGQGLE...</td>\n",
       "      <td>526148</td>\n",
       "      <td>DVVMTQSPLSLPVILGQPASISCRSPQSLEYVDGNTYLTWFQQRPG...</td>\n",
       "      <td>463742</td>\n",
       "      <td>QSVLTQPPSASGTPGQRVTISCSGSSSNIGGNSVNWYQHLPGTAPK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369593</th>\n",
       "      <td>99455</td>\n",
       "      <td>98898</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLKLSCAASGFTFSGSAIHWVRQASGKGLE...</td>\n",
       "      <td>74920</td>\n",
       "      <td>DIVMTQSPLSLPVTPGEPASISCRSSQSLLHGNGYNYLHWYLQKPG...</td>\n",
       "      <td>336068</td>\n",
       "      <td>QLVLTQSPSASASLGASVKLTCTLSSGHSSYVIAWHQQQPEKGPRF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369594</th>\n",
       "      <td>1532205</td>\n",
       "      <td>1514454</td>\n",
       "      <td>QVQLVESGGGVVQPGESLRLSCAASGFTFARYGFHWVRQAPGKGLE...</td>\n",
       "      <td>655174</td>\n",
       "      <td>DVVMTQSPLSLPVTLGQPASISCRSSQSLVYSDGNIYLSWFHQRPG...</td>\n",
       "      <td>205064</td>\n",
       "      <td>QSALTQPASVSGSPGQSITISCTGTSSDVGSYNLVSWYQQHPGKAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369595</th>\n",
       "      <td>789233</td>\n",
       "      <td>786881</td>\n",
       "      <td>EVQLVESGGGLVKPGGSLRLSCAASGFTFSNAWMSWVRQAPGKGLE...</td>\n",
       "      <td>83</td>\n",
       "      <td>DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPG...</td>\n",
       "      <td>9062</td>\n",
       "      <td>QSALTQPASVSGSPGQSITISCTGTSSDVGGYNYVSWYQQHPGKAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369596</th>\n",
       "      <td>791377</td>\n",
       "      <td>789025</td>\n",
       "      <td>EVQLLESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLE...</td>\n",
       "      <td>276930</td>\n",
       "      <td>DIVMTQTPLSLSVTPGQPASISCKSSQSLLHSDGKTYLYWYLQKPG...</td>\n",
       "      <td>127851</td>\n",
       "      <td>QSALTQPASVSGSPGQSITISCTGTSSDVGSYNLVSWYRQHPGKAP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369597 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pair_id  heavy_id                                              heavy  \\\n",
       "0        605842    604074  QVQLQESGPGLVKPSETLSLTCTVSGGSISSYYWSWIRQPPGKGLE...   \n",
       "1       1588716   1570796  QVQLVQSGAEVKTPEASVKLSCKTSGYTFTSYYIHWVRQAPGQGLE...   \n",
       "2        934058    931467  EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLE...   \n",
       "3       1047359   1044321  EVQLVESGGGLVKPGGSLRLSCAASGFTFSNAWMSWVRQAPGKGLE...   \n",
       "4        761110    758895  QVQLVQSGDEVREPGASVKVSCKASGDTLSSHGVTWVRQAPGQRLE...   \n",
       "...         ...       ...                                                ...   \n",
       "369592  1350039   1340727  QVQLVQSGTEVKKPGASVTVSCKAAGYTFANYGVSWVRQAPGQGLE...   \n",
       "369593    99455     98898  EVQLVESGGGLVQPGGSLKLSCAASGFTFSGSAIHWVRQASGKGLE...   \n",
       "369594  1532205   1514454  QVQLVESGGGVVQPGESLRLSCAASGFTFARYGFHWVRQAPGKGLE...   \n",
       "369595   789233    786881  EVQLVESGGGLVKPGGSLRLSCAASGFTFSNAWMSWVRQAPGKGLE...   \n",
       "369596   791377    789025  EVQLLESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLE...   \n",
       "\n",
       "        light_id_pos                                          light_pos  \\\n",
       "0               3608  SYVLTQPPSVSVAPGKTARITCGGNNIGSKSVHWYQQKPGQAPVLV...   \n",
       "1             201867  QAVVTQEPSLTVSPGGTVTLTCGSSTGAVTSGHYPYWFQQKPGQAP...   \n",
       "2                723  DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...   \n",
       "3             327738  DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...   \n",
       "4             268698  DVQMTQSPSTLSASVGDRVTITCRASQSISRSLAWYQQHPGRVPKL...   \n",
       "...              ...                                                ...   \n",
       "369592        526148  DVVMTQSPLSLPVILGQPASISCRSPQSLEYVDGNTYLTWFQQRPG...   \n",
       "369593         74920  DIVMTQSPLSLPVTPGEPASISCRSSQSLLHGNGYNYLHWYLQKPG...   \n",
       "369594        655174  DVVMTQSPLSLPVTLGQPASISCRSSQSLVYSDGNIYLSWFHQRPG...   \n",
       "369595            83  DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPG...   \n",
       "369596        276930  DIVMTQTPLSLSVTPGQPASISCKSSQSLLHSDGKTYLYWYLQKPG...   \n",
       "\n",
       "        light_id_neg                                          light_neg  \n",
       "0             338246  DIQMTQSPSSLSASVGDRVTITCRASQSISNYLNWYQQKPEKVPKL...  \n",
       "1             581364  DIQMTQSPSTLSASVGDRVTITCRASQSFSRWLAWYQQKPGKAPKL...  \n",
       "2             545684  SYVLTQPPSVSVAPGQTATITCGGNNIGSKVVHWYQQRPGQAPILV...  \n",
       "3              28102  QPVLTQPPSASASLGASVTLTCTLSSGYSNYKVDWYQQRPGKGPRF...  \n",
       "4             302895  QSVLTQPPSVSGAPGQTVTISCTGSSSNIGAGYDVHWYQQLPGTAP...  \n",
       "...              ...                                                ...  \n",
       "369592        463742  QSVLTQPPSASGTPGQRVTISCSGSSSNIGGNSVNWYQHLPGTAPK...  \n",
       "369593        336068  QLVLTQSPSASASLGASVKLTCTLSSGHSSYVIAWHQQQPEKGPRF...  \n",
       "369594        205064  QSALTQPASVSGSPGQSITISCTGTSSDVGSYNLVSWYQQHPGKAP...  \n",
       "369595          9062  QSALTQPASVSGSPGQSITISCTGTSSDVGGYNYVSWYQQHPGKAP...  \n",
       "369596        127851  QSALTQPASVSGSPGQSITISCTGTSSDVGSYNLVSWYRQHPGKAP...  \n",
       "\n",
       "[369597 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = '../datasets/new/test/test.csv'\n",
    "\n",
    "df = pd.read_csv(test_data, index_col=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c9a505-01e4-4366-a63c-08b549d70881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82c6d5d-1220-4fb6-84d2-6cb655ff7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: ../results/classification/IgBert_only_v/long_training/\n",
      "Retrieving the dataset...\n",
      "Reading ../datasets/new/test/test.csv...\n",
      "Dataset of size 369597\n",
      "Load the model...\n",
      "Retrieve the tokenizer...\n",
      "Tokenizer checkpoint: Exscientia/IgBert\n",
      "Start evaluating...\n",
      "Number of batches: 11550.\n",
      "Select only the first 11550 batches\n",
      "Model: ClassificationFromAveraging\n",
      "Device detected: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 11550/11550 [2:41:14<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "def evaluate(name,\n",
    "             test_data, subsample, batch_size,\n",
    "             model_name, model_checkpoint, tokenizer_checkpoint, eval_batches):\n",
    "\n",
    "    location = r'../results/classification/{}/'.format(name)\n",
    "    print('Location: {}'.format(location))\n",
    "    \n",
    "    # Get the data\n",
    "    print('Retrieving the dataset...')\n",
    "    test_ds, hyperpar = utils.get_test_dataset(test_data, subsample=subsample)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    # Load the model\n",
    "    print('Load the model...')\n",
    "    state_dict = torch.load('{}/model.pt'.format(location), weights_only=True)\n",
    "    model = utils.load_model(model_name, checkpoint=model_checkpoint, state_dict=state_dict)\n",
    "\n",
    "    # Get the tokenizer\n",
    "    print('Retrieve the tokenizer...')\n",
    "    if tokenizer_checkpoint is None: tokenizer_checkpoint = model_checkpoint\n",
    "    tokenizer = utils.retrieve_tokenizer(tokenizer_checkpoint)\n",
    "\n",
    "    logits = utils.evaluate_test(model, test_dl, metrics=None, eval_batches=None,\n",
    "                                 tokenizer=tokenizer)\n",
    "\n",
    "    logits.to_csv('{}/logits_val.csv'.format(location))\n",
    "\n",
    "x = evaluate('IgBert_only_v/long_training', \n",
    "             test_data, None, 32,\n",
    "             'average', 'Exscientia/IgBert', None, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8609e34c-9a2a-44da-9f3b-ef10d045afd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "sum(x, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf8c85-95a2-4f27-8859-6bc42a32cb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c9c424-084e-46b9-a6b3-f4ff055f9049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in cpuinfo: prctl(PR_SVE_GET_VL) failed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52e9e145-903f-4919-930f-4318eb68a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001]\n",
      "[9.7e-05]\n",
      "[9.4e-05]\n",
      "[9.099999999999999e-05]\n",
      "[8.799999999999998e-05]\n",
      "[8.499999999999999e-05]\n",
      "[8.199999999999999e-05]\n",
      "[7.899999999999998e-05]\n",
      "[7.599999999999999e-05]\n",
      "[7.299999999999999e-05]\n",
      "[6.999999999999998e-05]\n",
      "[6.699999999999999e-05]\n",
      "[6.399999999999998e-05]\n",
      "[6.0999999999999985e-05]\n",
      "[5.799999999999998e-05]\n",
      "[5.499999999999998e-05]\n",
      "[5.199999999999998e-05]\n",
      "[4.8999999999999985e-05]\n",
      "[4.5999999999999986e-05]\n",
      "[4.299999999999999e-05]\n",
      "[3.999999999999999e-05]\n",
      "[3.699999999999999e-05]\n",
      "[3.399999999999999e-05]\n",
      "[3.0999999999999995e-05]\n",
      "[2.7999999999999993e-05]\n",
      "[2.499999999999999e-05]\n",
      "[2.1999999999999993e-05]\n",
      "[1.899999999999999e-05]\n",
      "[1.5999999999999992e-05]\n",
      "[1.2999999999999994e-05]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n",
      "[9.999999999999994e-06]\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(10, 10)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "sched = optim.lr_scheduler.LinearLR(optimizer,\n",
    "                       start_factor=1, end_factor=0.1, total_iters=30)\n",
    "\n",
    "for _ in range(60):\n",
    "    print(sched.get_last_lr())\n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "690ccbad-bcf1-403e-91c7-14eccfb64cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[9e-05]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n",
      "[0.0001]\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(10, 10)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "sched = optim.lr_scheduler.ConstantLR(optimizer,\n",
    "                       factor=0.9, total_iters=30)\n",
    "\n",
    "for _ in range(40):\n",
    "    print(sched.get_last_lr())\n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52e76cac-2310-48e7-9116-050dd9ffaa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001]\n",
      "[9e-05]\n",
      "[8.1e-05]\n",
      "[7.290000000000001e-05]\n",
      "[6.561000000000002e-05]\n",
      "[5.904900000000002e-05]\n",
      "[5.314410000000002e-05]\n",
      "[4.782969000000002e-05]\n",
      "[4.304672100000002e-05]\n",
      "[3.874204890000002e-05]\n",
      "[3.4867844010000016e-05]\n",
      "[3.138105960900002e-05]\n",
      "[2.8242953648100018e-05]\n",
      "[2.5418658283290016e-05]\n",
      "[2.2876792454961016e-05]\n",
      "[2.0589113209464913e-05]\n",
      "[1.8530201888518422e-05]\n",
      "[1.667718169966658e-05]\n",
      "[1.5009463529699922e-05]\n",
      "[1.350851717672993e-05]\n",
      "[1.2157665459056937e-05]\n",
      "[1.0941898913151244e-05]\n",
      "[9.84770902183612e-06]\n",
      "[8.862938119652508e-06]\n",
      "[7.976644307687257e-06]\n",
      "[7.1789798769185315e-06]\n",
      "[6.461081889226678e-06]\n",
      "[5.81497370030401e-06]\n",
      "[5.23347633027361e-06]\n",
      "[4.710128697246249e-06]\n",
      "[4.239115827521624e-06]\n",
      "[3.815204244769462e-06]\n",
      "[3.4336838202925156e-06]\n",
      "[3.090315438263264e-06]\n",
      "[2.7812838944369375e-06]\n",
      "[2.503155504993244e-06]\n",
      "[2.2528399544939195e-06]\n",
      "[2.0275559590445276e-06]\n",
      "[1.824800363140075e-06]\n",
      "[1.6423203268260674e-06]\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(10, 10)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "sched = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                       gamma=0.9)\n",
    "\n",
    "for _ in range(40):\n",
    "    print(sched.get_last_lr())\n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0386602f-cf98-4912-a574-68fa873c2d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001]\n",
      "0.0001\n",
      "[9e-05]\n",
      "9e-05\n",
      "[8.1e-05]\n",
      "8.1e-05\n",
      "[7.290000000000001e-05]\n",
      "7.290000000000001e-05\n",
      "[6.561000000000002e-05]\n",
      "6.561000000000002e-05\n",
      "[5.904900000000002e-05]\n",
      "5.904900000000002e-05\n",
      "[5.314410000000002e-05]\n",
      "5.314410000000002e-05\n",
      "[4.782969000000002e-05]\n",
      "4.782969000000002e-05\n",
      "[4.304672100000002e-05]\n",
      "4.304672100000002e-05\n",
      "[3.874204890000002e-05]\n",
      "3.874204890000002e-05\n",
      "[3.4867844010000016e-05]\n",
      "3.4867844010000016e-05\n",
      "[3.138105960900002e-05]\n",
      "3.138105960900002e-05\n",
      "[2.8242953648100018e-05]\n",
      "2.8242953648100018e-05\n",
      "[2.5418658283290016e-05]\n",
      "2.5418658283290016e-05\n",
      "[2.2876792454961016e-05]\n",
      "2.2876792454961016e-05\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n",
      "[0.0001]\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(10, 10)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "sched = optim.lr_scheduler.SequentialLR(optimizer,\n",
    "                                        [optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9),\n",
    "                                         optim.lr_scheduler.ConstantLR(optimizer, 1, 1)],\n",
    "                                        [15])\n",
    "\n",
    "for _ in range(40):\n",
    "    print(sched.get_last_lr())\n",
    "    print(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "    sched.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
